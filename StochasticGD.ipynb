{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA68iuasHVonU7uMWTByEx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lifeisforty2/Lifeisforty2.github.io/blob/main/StochasticGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnIbjcIry50t"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Machine Learning, Stochastic Gradient Descent\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import all required libraries\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Rjczrz96zC5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "basePath = \"/content/drive/My Drive/Colab Notebooks/Ai/\""
      ],
      "metadata": {
        "id": "1bpaP12WzEcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data file name variables\n",
        "train = basePath + \"gd-train.dat\"\n",
        "test = basePath + \"gd-test.dat\"\n",
        "'''\n",
        "import os\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Ai/'\n",
        "file_list = os.listdir(folder_path)\n",
        "print(file_list)\n",
        "'''"
      ],
      "metadata": {
        "id": "ZTD_IbMVzIdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the training and testing data files\n",
        "trainData = pd.read_csv(train, sep='\\s+', header=None)\n",
        "testData = pd.read_csv(test, sep='\\s+', header=None)"
      ],
      "metadata": {
        "id": "_ed2VPruzJ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation Function - implement Sigmoid\n",
        "def activation_function(h):\n",
        "    # given 'h' compute and return 'z' based on the activation function implemented\n",
        "    z = 1/(1+np.exp(-h))\n",
        "    return z"
      ],
      "metadata": {
        "id": "K1kzTjOczLAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the given training dataset and the learning rate\n",
        "# return the \"weights\" learnt for the perceptron - include the weight assocaited with bias as the last entry\n",
        "def train(train_data, learning_rate=0.05):\n",
        "    train_data = train_data.to_numpy()\n",
        "    # initialize weights to 0\n",
        "    weights = np.zeros(train_data.shape[1] - 1)\n",
        "    weights = weights.astype(float)\n",
        "    # go through each training data instance\n",
        "    for index, rows in enumerate(train_data):\n",
        "        # get 'x' as one multi-variate data instance and 'y' as the ground truth class label\n",
        "\n",
        "        if index == 0:\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "        x = rows[:-1]\n",
        "        y = rows[-1]\n",
        "        x = x.astype(float)\n",
        "        # y is a string, make it a float\n",
        "        y = float(y)\n",
        "        # print y type\n",
        "        # obtain h(x)\n",
        "        # b = position, b = bias\n",
        "        b = weights[-1]\n",
        "        h = np.dot(weights, x) + b\n",
        "\n",
        "        # call the activation function with 'h' as parameter to obtain 'z'\n",
        "        z = activation_function(h)\n",
        "        # update all weights individually using learning_rate, (y-z), and the corresponding 'x' value\n",
        "        for i in range(len(weights)):\n",
        "            weights[i] = weights[i] + learning_rate * (y - z) * x[i]\n",
        "\n",
        "        # update the bias weight\n",
        "        weights[-1] = weights[-1] + learning_rate * (y - z) * 1\n",
        "    # return the final learnt weights\n",
        "    return weights\n"
      ],
      "metadata": {
        "id": "7ORaeG5kzMdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model (weights learnt) using the given test dataset\n",
        "# return the accuracy value\n",
        "def test(test_data, weights, threshold):\n",
        "    # go through each testing data instance\n",
        "    # initialize the positive and negative instances to 0\n",
        "    pos = 0\n",
        "    neg = 0\n",
        "    test_data = test_data.to_numpy()\n",
        "    for index, rows in enumerate(test_data):\n",
        "        # get 'x' as one multi-variate data instance and 'y' as the ground truth class label\n",
        "        if index == 0:\n",
        "            continue\n",
        "        x = rows[:-1]\n",
        "        y = rows[-1]\n",
        "        x = x.astype(float)\n",
        "        y = float(y)\n",
        "        # obtain h(x)\n",
        "        b = weights[-1]\n",
        "        h = np.dot(weights, x) + b\n",
        "        # call the activation function with 'h' as parameter to obtain 'z'\n",
        "        z = activation_function(h)\n",
        "        # use 'threshold' to convert 'z' to either 0 or 1 so as to match to the ground truth binary labels\n",
        "        if z >= threshold:\n",
        "            z = 1\n",
        "        else:\n",
        "            z = 0\n",
        "\n",
        "        # compare the thresholded 'z' with 'y' to calculate the positive and negative instances for calculating accuracy\n",
        "        if z == y:\n",
        "            pos += 1\n",
        "        else:\n",
        "            neg += 1\n",
        "    # calculate the accuracy value\n",
        "    # return the accuracy value for the given test dataset\n",
        "    accuracy = pos / (pos + neg)\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "mnbhT1vMzN_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent function\n",
        "def gradient_descent(df_train, df_test, learning_rate=0.05, threshold=0.5):\n",
        "    # call the train function to train the model and obtain the weights\n",
        "    weights = train(df_train, learning_rate)\n",
        "    # call the test function with the training dataset to obtain the training accuracy\n",
        "    trainAccuracy = test(df_train, weights, threshold)\n",
        "    # call the test function with the testing dataset to obtain the testing accuracy\n",
        "    testAccuracy = test(df_test, weights, threshold)\n",
        "    # return (trainAccuracy, testAccuracy)\n",
        "    return (trainAccuracy, testAccuracy)"
      ],
      "metadata": {
        "id": "7-SqSSq4zQf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold of 0.5 will be used to classify the instance for the test. If the value is >= 0.5, classify as 1 or else 0.\n",
        "threshold = 0.5\n"
      ],
      "metadata": {
        "id": "sGvdlGQ3zSXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main algorithm loop\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "# Loop through all the different learning rates [0.05 to 1.0] with an increment of 0.05\n",
        "    learning_rates = np.arange(0.05, 1.05, 0.05)\n",
        "    # if decimal place is > 2, round it to 2 decimal places'\n",
        "    learning_rates = np.round(learning_rates, 2)\n",
        "    # For each learning rate selected, call the gradient descent function to obtain the train and test accuracy values\n",
        "    for learning_rate in learning_rates:\n",
        "        # call the gradient_descent function to obtain the train and test accuracy values\n",
        "        trainAccuracy, testAccuracy = gradient_descent(trainData, testData, learning_rate, threshold)\n",
        "        # Print both the accuracy values as \"Accuracy for LR of 0.1 on Training set = x %\" OR \"Accuracy for LR of 0.1 on Testing set = x %\"\n",
        "        print(\"Accuracy for LR of\", learning_rate, \"on Training set =\", trainAccuracy * 100, \"%\")\n",
        "        print(\"Accuracy for LR of\", learning_rate, \"on Testing set =\", testAccuracy * 100, \"%\")\n",
        "    # Print both the accuracy values as \"Accuracy for LR of 0.1 on Training set = x %\" OR \"Accuracy for LR of 0.1 on Testing set = x %\"\n",
        "\n"
      ],
      "metadata": {
        "id": "rhU3_unizSWV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}