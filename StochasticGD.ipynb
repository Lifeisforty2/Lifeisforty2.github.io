{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxR6XC1y75t77IgFjbyvQ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lifeisforty2/Lifeisforty2.github.io/blob/main/StochasticGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XnIbjcIry50t",
        "outputId": "2d40bb67-a12a-44c7-ee76-c2e95f334381"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nMachine Learning, Stochastic Gradient Descent\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "Machine Learning, Stochastic Gradient Descent\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import all required libraries\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Rjczrz96zC5a"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "drive.mount('/content/drive')\n",
        "basePath = \"/content/drive/My Drive/Colab Notebooks/Ai/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bpaP12WzEcE",
        "outputId": "1bac028c-9397-478b-87d5-4e54ae262d8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data file name variables\n",
        "train = basePath + \"gd-train.dat\"\n",
        "test = basePath + \"gd-test.dat\"\n",
        "'''\n",
        "import os\n",
        "folder_path = '/content/drive/My Drive/Colab Notebooks/Ai/'\n",
        "file_list = os.listdir(folder_path)\n",
        "print(file_list)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZTD_IbMVzIdz",
        "outputId": "2065c009-b41c-40f0-ddbb-62c1761b8508"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nimport os\\nfolder_path = '/content/drive/My Drive/Colab Notebooks/Ai/'\\nfile_list = os.listdir(folder_path)\\nprint(file_list)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the training and testing data files\n",
        "trainData = pd.read_csv(train, sep='\\s+', header=None)\n",
        "testData = pd.read_csv(test, sep='\\s+', header=None)"
      ],
      "metadata": {
        "id": "_ed2VPruzJ48"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation Function - implement Sigmoid\n",
        "def activation_function(h):\n",
        "    # given 'h' compute and return 'z' based on the activation function implemented\n",
        "    z = 1/(1+np.exp(-h))\n",
        "    return z"
      ],
      "metadata": {
        "id": "K1kzTjOczLAw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model using the given training dataset and the learning rate\n",
        "# return the \"weights\" learnt for the perceptron - include the weight assocaited with bias as the last entry\n",
        "def train(train_data, learning_rate=0.05):\n",
        "    train_data = train_data.to_numpy()\n",
        "    # initialize weights to 0\n",
        "    weights = np.zeros(train_data.shape[1] - 1)\n",
        "    weights = weights.astype(float)\n",
        "    # go through each training data instance\n",
        "    for index, rows in enumerate(train_data):\n",
        "        # get 'x' as one multi-variate data instance and 'y' as the ground truth class label\n",
        "\n",
        "        if index == 0:\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "        x = rows[:-1]\n",
        "        y = rows[-1]\n",
        "        x = x.astype(float)\n",
        "        # y is a string, make it a float\n",
        "        y = float(y)\n",
        "        # print y type\n",
        "        # obtain h(x)\n",
        "        # b = position, b = bias\n",
        "        b = weights[-1]\n",
        "        h = np.dot(weights, x) + b\n",
        "\n",
        "        # call the activation function with 'h' as parameter to obtain 'z'\n",
        "        z = activation_function(h)\n",
        "        # update all weights individually using learning_rate, (y-z), and the corresponding 'x' value\n",
        "        for i in range(len(weights)):\n",
        "            weights[i] = weights[i] + learning_rate * (y - z) * x[i]\n",
        "\n",
        "        # update the bias weight\n",
        "        weights[-1] = weights[-1] + learning_rate * (y - z) * 1\n",
        "    # return the final learnt weights\n",
        "    return weights\n"
      ],
      "metadata": {
        "id": "7ORaeG5kzMdt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model (weights learnt) using the given test dataset\n",
        "# return the accuracy value\n",
        "def test(test_data, weights, threshold):\n",
        "    # go through each testing data instance\n",
        "    # initialize the positive and negative instances to 0\n",
        "    pos = 0\n",
        "    neg = 0\n",
        "    test_data = test_data.to_numpy()\n",
        "    for index, rows in enumerate(test_data):\n",
        "        # get 'x' as one multi-variate data instance and 'y' as the ground truth class label\n",
        "        if index == 0:\n",
        "            continue\n",
        "        x = rows[:-1]\n",
        "        y = rows[-1]\n",
        "        x = x.astype(float)\n",
        "        y = float(y)\n",
        "        # obtain h(x)\n",
        "        b = weights[-1]\n",
        "        h = np.dot(weights, x) + b\n",
        "        # call the activation function with 'h' as parameter to obtain 'z'\n",
        "        z = activation_function(h)\n",
        "        # use 'threshold' to convert 'z' to either 0 or 1 so as to match to the ground truth binary labels\n",
        "        if z >= threshold:\n",
        "            z = 1\n",
        "        else:\n",
        "            z = 0\n",
        "\n",
        "        # compare the thresholded 'z' with 'y' to calculate the positive and negative instances for calculating accuracy\n",
        "        if z == y:\n",
        "            pos += 1\n",
        "        else:\n",
        "            neg += 1\n",
        "    # calculate the accuracy value\n",
        "    # return the accuracy value for the given test dataset\n",
        "    accuracy = pos / (pos + neg)\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "mnbhT1vMzN_N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent function\n",
        "def gradient_descent(df_train, df_test, learning_rate=0.05, threshold=0.5):\n",
        "    # call the train function to train the model and obtain the weights\n",
        "    weights = train(df_train, learning_rate)\n",
        "    # call the test function with the training dataset to obtain the training accuracy\n",
        "    trainAccuracy = test(df_train, weights, threshold)\n",
        "    # call the test function with the testing dataset to obtain the testing accuracy\n",
        "    testAccuracy = test(df_test, weights, threshold)\n",
        "    # return (trainAccuracy, testAccuracy)\n",
        "    return (trainAccuracy, testAccuracy)"
      ],
      "metadata": {
        "id": "7-SqSSq4zQf2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold of 0.5 will be used to classify the instance for the test. If the value is >= 0.5, classify as 1 or else 0.\n",
        "threshold = 0.5\n"
      ],
      "metadata": {
        "id": "sGvdlGQ3zSXZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main algorithm loop\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "# Loop through all the different learning rates [0.05 to 1.0] with an increment of 0.05\n",
        "    learning_rates = np.arange(0.05, 1.05, 0.05)\n",
        "    # if decimal place is > 2, round it to 2 decimal places'\n",
        "    learning_rates = np.round(learning_rates, 2)\n",
        "    # For each learning rate selected, call the gradient descent function to obtain the train and test accuracy values\n",
        "    for learning_rate in learning_rates:\n",
        "        # call the gradient_descent function to obtain the train and test accuracy values\n",
        "        trainAccuracy, testAccuracy = gradient_descent(trainData, testData, learning_rate, threshold)\n",
        "        # Print both the accuracy values as \"Accuracy for LR of 0.1 on Training set = x %\" OR \"Accuracy for LR of 0.1 on Testing set = x %\"\n",
        "        print(\"Accuracy for LR of\", learning_rate, \"on Training set =\", trainAccuracy * 100, \"%\")\n",
        "        print(\"Accuracy for LR of\", learning_rate, \"on Testing set =\", testAccuracy * 100, \"%\")\n",
        "    # Print both the accuracy values as \"Accuracy for LR of 0.1 on Training set = x %\" OR \"Accuracy for LR of 0.1 on Testing set = x %\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhU3_unizSWV",
        "outputId": "90459f05-ea44-4e2c-d594-bbfa4a50e6d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for LR of 0.05 on Training set = 68.0 %\n",
            "Accuracy for LR of 0.05 on Testing set = 72.25 %\n",
            "Accuracy for LR of 0.1 on Training set = 68.0 %\n",
            "Accuracy for LR of 0.1 on Testing set = 72.25 %\n",
            "Accuracy for LR of 0.15 on Training set = 68.0 %\n",
            "Accuracy for LR of 0.15 on Testing set = 72.0 %\n",
            "Accuracy for LR of 0.2 on Training set = 68.0 %\n",
            "Accuracy for LR of 0.2 on Testing set = 71.75 %\n",
            "Accuracy for LR of 0.25 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.25 on Testing set = 71.25 %\n",
            "Accuracy for LR of 0.3 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.3 on Testing set = 71.75 %\n",
            "Accuracy for LR of 0.35 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.35 on Testing set = 71.0 %\n",
            "Accuracy for LR of 0.4 on Training set = 71.0 %\n",
            "Accuracy for LR of 0.4 on Testing set = 70.25 %\n",
            "Accuracy for LR of 0.45 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.45 on Testing set = 70.0 %\n",
            "Accuracy for LR of 0.5 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.5 on Testing set = 69.25 %\n",
            "Accuracy for LR of 0.55 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.55 on Testing set = 68.5 %\n",
            "Accuracy for LR of 0.6 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.6 on Testing set = 68.0 %\n",
            "Accuracy for LR of 0.65 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.65 on Testing set = 66.25 %\n",
            "Accuracy for LR of 0.7 on Training set = 66.0 %\n",
            "Accuracy for LR of 0.7 on Testing set = 66.25 %\n",
            "Accuracy for LR of 0.75 on Training set = 67.0 %\n",
            "Accuracy for LR of 0.75 on Testing set = 65.75 %\n",
            "Accuracy for LR of 0.8 on Training set = 68.0 %\n",
            "Accuracy for LR of 0.8 on Testing set = 65.75 %\n",
            "Accuracy for LR of 0.85 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.85 on Testing set = 66.0 %\n",
            "Accuracy for LR of 0.9 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.9 on Testing set = 65.25 %\n",
            "Accuracy for LR of 0.95 on Training set = 69.0 %\n",
            "Accuracy for LR of 0.95 on Testing set = 65.25 %\n",
            "Accuracy for LR of 1.0 on Training set = 69.0 %\n",
            "Accuracy for LR of 1.0 on Testing set = 65.75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "it_ArmOEztuI"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}